{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Ollama integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To break down what LangChain is, let\\'s consider the following steps:\\n\\n1. **Break down the name**: \"Lang\" is short for \"Language\", so it suggests that LangChain has something to do with natural language processing (NLP) or human-computer interaction.\\n\\n2. **Chain implies connection or linking**: The word \"chain\" implies a sequence of elements or processes connected in some way. This could suggest that LangChain is about connecting different pieces of information, tasks, or even systems together.\\n\\n3. **Considering the context of technology and AI**: Given the tech-oriented nature of the name, it\\'s likely that LangChain has something to do with artificial intelligence (AI) or machine learning (ML). These fields often involve complex connections between data, algorithms, and models.\\n\\n4. **Linking language and AI/ML**: Combining these insights suggests that LangChain might be an AI-powered tool for handling natural language interactions. This could include tasks like chatbots, text analysis, or perhaps even more advanced applications like conversational AI.\\n\\n5. **Researching further**: Given the speculative nature of our breakdown, it would be beneficial to look up what LangChain actually is in real-world tech and AI development.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.1:8b\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Ollama integration - Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is an open-source framework for building conversational AI models and applications. It's designed to make it easier to create, integrate, and manage large language models (LLMs) in various use cases.\\n\\nLangChain provides a set of tools and APIs that enable developers to:\\n\\n1. **Integrate LLMs** into their applications: LangChain allows you to easily connect popular LLMs like LLaMA, BERT, or T5 to your application.\\n2. **Build conversational interfaces**: With LangChain, you can create interactive chatbots, voice assistants, or other conversational interfaces that can understand and respond to user queries.\\n3. **Manage and optimize LLM interactions**: The framework provides features for caching, throttling, and monitoring LLM requests to ensure efficient and scalable performance.\\n\\nLangChain is built on top of popular libraries like PyTorch and TensorFlow, making it compatible with a wide range of development environments.\\n\\nIts primary goals are to:\\n\\n1. Simplify the process of working with large language models\\n2. Improve the integration of these models into applications\\n3. Enhance the scalability and performance of conversational AI systems\\n\\nOverall, LangChain aims to democratize access to advanced LLM capabilities, enabling developers without extensive NLP expertise to build powerful conversational interfaces.\\n\\nIs there anything else you'd like to know about LangChain?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-04-08T14:08:29.648574Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5244904250, 'load_duration': 12816500, 'prompt_eval_count': 29, 'prompt_eval_duration': 94430042, 'eval_count': 277, 'eval_duration': 5137085958, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f4947478-71bf-4f12-8825-b7d3dcc41606-0', usage_metadata={'input_tokens': 29, 'output_tokens': 277, 'total_tokens': 306})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant answering user queries.\"),\n",
    "    (\"human\", \"What is LangChain?\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-de and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name='jinaai/jina-embeddings-v2-base-de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Memory database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "file_path = \"./pubhub_docs/Warum Lachen gesund ist_DE.pdf\"\n",
    "loader = PyMuPDFLoader(file_path,\n",
    "        mode=\"single\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext',\n",
       " 'creator': 'Safari',\n",
       " 'creationdate': \"D:20250324210225Z00'00'\",\n",
       " 'source': './pubhub_docs/Warum Lachen gesund ist_DE.pdf',\n",
       " 'file_path': './pubhub_docs/Warum Lachen gesund ist_DE.pdf',\n",
       " 'total_pages': 4,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'Warum Lachen gesund ist',\n",
       " 'author': 'David Massimo',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': \"D:20250324210225Z00'00'\",\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20250324210225Z00'00'\",\n",
       " 'creationDate': \"D:20250324210225Z00'00'\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Loading + Parsing files\n",
    "#\n",
    "\n",
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import PyMuPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"./pubhub_docs/\",\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    # blob_parser=PyMuPDFParser(mode=\"single\"),\n",
    "    blob_parser=PyMuPDFParser(mode=\"single\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs[5].page_content)\n",
    "# docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization - Doc splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 68 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ee8affaa-657a-49bb-97c4-b3305e3dcca4', '2b640e6b-2d5e-4955-81c1-a7d8ce16bde0', 'f8cb7bcb-6017-4c76-9f50-e68972fe3868']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an helpful chatbot to support workers at Public Value Technologies gmbh (also known as pub.tech). \n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "If the query is in German you reply in german, otherwise in english.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CitedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and cite the sources used.\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources.\",\n",
    "    )\n",
    "    citations: List[int] = Field(\n",
    "        ...,\n",
    "        description=\"The integer IDs of the SPECIFIC sources which justify the answer.\",\n",
    "    )\n",
    "\n",
    "def format_docs_with_id(docs: List[Document]) -> str:\n",
    "    formatted = [\n",
    "        f\"Source ID: {i}\\nArticle Title: {doc.metadata['source']}\\nArticle Snippet: {doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    # answer: str\n",
    "    answer: CitedAnswer\n",
    "\n",
    "# Nodes\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"],k=3)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# def generate(state: State):    \n",
    "#     docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "#     messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "#     # print(messages)\n",
    "#     response = llm.invoke(messages)\n",
    "    # return {\"answer\": response}\n",
    "\n",
    "def generate(state: State):\n",
    "    formatted_docs = format_docs_with_id(state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": formatted_docs})\n",
    "    structured_llm = llm.with_structured_output(CitedAnswer)\n",
    "    response = structured_llm.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "# Control flow of the program (langgrap)h\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Context: [Document(id='96471a83-58fe-446d-b81b-1440a229657f', \"\n",
      " \"metadata={'producer': 'macOS Version 15.3.2 (Build 24D81) Quartz \"\n",
      " \"PDFContext', 'creator': 'Safari', 'creationdate': \"\n",
      " '\"D:20250324210537Z00\\'00\\'\", \\'source\\': \\'pubhub_docs/Business trips and '\n",
      " \"travel expense guidelines.pdf', 'file_path': 'pubhub_docs/Business trips and \"\n",
      " \"travel expense guidelines.pdf', 'total_pages': 3, 'format': 'PDF 1.3', \"\n",
      " \"'title': 'Business trips and travel expense guidelines', 'author': 'David \"\n",
      " \"Massimo', 'subject': '', 'keywords': '', 'moddate': \"\n",
      " '\"D:20250324210537Z00\\'00\\'\", \\'trapped\\': \\'\\', \\'modDate\\': '\n",
      " '\"D:20250324210537Z00\\'00\\'\", \\'creationDate\\': \"D:20250324210537Z00\\'00\\'\", '\n",
      " \"'start_index': 2460}, page_content='24/03/25, 22:05\\\\nBusiness trips and \"\n",
      " 'travel expense guidelines\\\\nPage 2 of '\n",
      " '3\\\\nhttps://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx\\\\nThe '\n",
      " 'balance between meeting business requirements, complying with '\n",
      " 'legal\\\\nrequirements and ï¬nancial responsibility is crucial.\\\\nBusiness '\n",
      " 'Trips\\\\nBusiness Trips\\\\nBusiness Trips\\\\nBusiness Trips\\\\nTravel '\n",
      " 'guidelines\\\\nTravel guidelines\\\\nTravel guidelines\\\\nTravel '\n",
      " 'guidelines\\\\n\\\\x0c24/03/25, 22:05\\\\nBusiness trips and travel expense '\n",
      " 'guidelines\\\\nPage 3 of '\n",
      " \"3\\\\nhttps://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx'), \"\n",
      " \"Document(id='926a8be1-5e23-4bc1-a29d-b411d63385c4', metadata={'producer': \"\n",
      " \"'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext', 'creator': 'Safari', \"\n",
      " '\\'creationdate\\': \"D:20250324210537Z00\\'00\\'\", \\'source\\': '\n",
      " \"'pubhub_docs/Business trips and travel expense guidelines.pdf', 'file_path': \"\n",
      " \"'pubhub_docs/Business trips and travel expense guidelines.pdf', \"\n",
      " \"'total_pages': 3, 'format': 'PDF 1.3', 'title': 'Business trips and travel \"\n",
      " \"expense guidelines', 'author': 'David Massimo', 'subject': '', 'keywords': \"\n",
      " '\\'\\', \\'moddate\\': \"D:20250324210537Z00\\'00\\'\", \\'trapped\\': \\'\\', '\n",
      " '\\'modDate\\': \"D:20250324210537Z00\\'00\\'\", \\'creationDate\\': '\n",
      " '\"D:20250324210537Z00\\'00\\'\", \\'start_index\\': 1671}, '\n",
      " \"page_content='transparently and to prevent abuse, we have drawn up \"\n",
      " 'corresponding\\\\ntransparently and to prevent abuse, we have drawn up '\n",
      " 'corresponding\\\\ntransparently and to prevent abuse, we have drawn up '\n",
      " 'corresponding\\\\nguidelines for our organization for requesting business '\n",
      " 'trips as well\\\\nguidelines for our organization for requesting business '\n",
      " 'trips as well\\\\nguidelines for our organization for requesting business '\n",
      " 'trips as well\\\\nguidelines for our organization for requesting business '\n",
      " 'trips as well\\\\nas travel expense guidelines.\\\\nas travel expense '\n",
      " 'guidelines.\\\\nas travel expense guidelines.\\\\nas travel expense '\n",
      " 'guidelines.\\\\n\\\\xa0\\\\nThis is because both employers and employees should be '\n",
      " 'aware of their\\\\nobligations and rights during business trips and act '\n",
      " 'accordingly to ensure\\\\nthat the trip runs smoothly and '\n",
      " 'safely.\\\\n\\\\x0c24/03/25, 22:05\\\\nBusiness trips and travel expense '\n",
      " 'guidelines\\\\nPage 2 of '\n",
      " \"3\\\\nhttps://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx'), \"\n",
      " \"Document(id='8607e590-a21c-4392-83c1-2e71416cd8c7', metadata={'producer': \"\n",
      " \"'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext', 'creator': 'Safari', \"\n",
      " '\\'creationdate\\': \"D:20250324210537Z00\\'00\\'\", \\'source\\': '\n",
      " \"'pubhub_docs/Business trips and travel expense guidelines.pdf', 'file_path': \"\n",
      " \"'pubhub_docs/Business trips and travel expense guidelines.pdf', \"\n",
      " \"'total_pages': 3, 'format': 'PDF 1.3', 'title': 'Business trips and travel \"\n",
      " \"expense guidelines', 'author': 'David Massimo', 'subject': '', 'keywords': \"\n",
      " '\\'\\', \\'moddate\\': \"D:20250324210537Z00\\'00\\'\", \\'trapped\\': \\'\\', '\n",
      " '\\'modDate\\': \"D:20250324210537Z00\\'00\\'\", \\'creationDate\\': '\n",
      " '\"D:20250324210537Z00\\'00\\'\", \\'start_index\\': 836}, page_content=\\'for '\n",
      " 'business trips.\\\\nfor business trips.\\\\nfor business trips.\\\\nfor business '\n",
      " 'trips.\\\\n\\\\xa0\\\\nIn addition to the Working Hours Act (ArbZG), which '\n",
      " 'contains regulations on\\\\nworking hours, rest breaks and rest periods, the '\n",
      " 'Federal Travel Expenses Act\\\\n(BRKG) stipulates, among other things, which '\n",
      " 'costs may be reimbursed in\\\\nconnection with business trips and to what '\n",
      " 'extent. In addition, tax and\\\\ninsurance aspects must also be taken into '\n",
      " 'account.\\\\n\\\\xa0\\\\nThe employer must ensure that employees are adequately '\n",
      " 'insured during\\\\nbusiness trips.\\\\n\\\\xa0\\\\nIn order to ensure that business '\n",
      " 'trips are handled fairly and\\\\nIn order to ensure that business trips are '\n",
      " 'handled fairly and\\\\nIn order to ensure that business trips are handled '\n",
      " 'fairly and\\\\nIn order to ensure that business trips are handled fairly '\n",
      " 'and\\\\ntransparently and to prevent abuse, we have drawn up '\n",
      " 'corresponding\\\\ntransparently and to prevent abuse, we have drawn up '\n",
      " 'corresponding\\\\ntransparently and to prevent abuse, we have drawn up '\n",
      " \"corresponding')]\\n\"\n",
      " '\\n')\n",
      "('Answer: answer=\"Please refer to the Business Trips and Travel Expense '\n",
      " 'Guidelines document (pubhub_docs/Business trips and travel expense '\n",
      " 'guidelines.pdf) on our SharePoint site. This will provide you with detailed '\n",
      " 'information on what to do when planning a business trip, including '\n",
      " 'regulations on working hours, rest breaks, and reimbursement of expenses. '\n",
      " \"Additionally, it's essential to ensure that you are adequately insured \"\n",
      " \"during the trip. If you're unsure about any aspect of a business trip, \"\n",
      " 'please consult your supervisor or HR department.\" citations=[1, 2]')\n",
      "pubhub_docs/Business trips and travel expense guidelines.pdf\n",
      "pubhub_docs/Business trips and travel expense guidelines.pdf\n"
     ]
    }
   ],
   "source": [
    "# result = graph.invoke({\"question\": \"Was soll ich tun um urlaub zu buchen at pub.tech?\"})\n",
    "result = graph.invoke({\"question\": \"What should I do when doing a businesss trip?\"})\n",
    "\n",
    "pprint.pp(f'Context: {result[\"context\"]}\\n\\n')\n",
    "pprint.pp(f'Answer: {result[\"answer\"]}')\n",
    "\n",
    "for cit in result[\"answer\"].citations:\n",
    "    print(result[\"context\"][cit].metadata[\"source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please refer to the Business Trips and Travel Expense Guidelines document (pubhub_docs/Business trips and travel expense guidelines.pdf) on our SharePoint site. This will provide you with detailed information on what to do when planning a business trip, including regulations on working hours, rest breaks, and reimbursement of expenses. Additionally, it's essential to ensure that you are adequately insured during the trip. If you're unsure about any aspect of a business trip, please consult your supervisor or HR department.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pubhub_docs/Business trips and travel expense guidelines.pdf'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"context\"][1].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'de-DE', 'score': 0.9999765157699585}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "model_name = 'qanastek/51-languages-classifier'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "res = classifier(\"was soll ich machen\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CitedAnswer(answer='5\\'11\"', citations=[3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CitedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and cite the sources used.\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources.\",\n",
    "    )\n",
    "    citations: List[int] = Field(\n",
    "        ...,\n",
    "        description=\"The integer IDs of the SPECIFIC sources which justify the answer.\",\n",
    "    )\n",
    "\n",
    "def format_docs_with_id(docs: List[Document]) -> str:\n",
    "    formatted = [\n",
    "        f\"Source ID: {i}\\nArticle Title: {doc.metadata['source']}\\nArticle Snippet: {doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)\n",
    "\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(CitedAnswer)\n",
    "\n",
    "example_q = \"\"\"What Brian's height?\n",
    "\n",
    "Source: 1\n",
    "Information: Suzy is 6'2\"\n",
    "\n",
    "Source: 2\n",
    "Information: Jeremiah is blonde\n",
    "\n",
    "Source: 3\n",
    "Information: Brian is 3 inches shorter than Suzy\"\"\"\n",
    "result = structured_llm.invoke(example_q)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pubhub_docs/FAQ - Workation_DE.pdf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Ollama integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# template = \"\"\"Question: {question}\n",
    "\n",
    "# Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.1:8b\")\n",
    "\n",
    "# chain = prompt | llm\n",
    "\n",
    "# chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Ollama integration - Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.1:8b\")\n",
    "\n",
    "# messages = [\n",
    "#     (\"system\", \"You are a helpful assistant answering user queries.\"),\n",
    "#     (\"human\", \"What is LangChain?\"),\n",
    "# ]\n",
    "# llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# embeddings = OllamaEmbeddings(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <BFAC0362-079C-3D60-A731-79532A75BA60> /Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/david/miniconda3/envs/hf_gpu/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/david/miniconda3/envs/hf_gpu/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name='jinaai/jina-embeddings-v2-base-de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Memory database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "file_path = \"./pubhub_docs/Warum Lachen gesund ist_DE.pdf\"\n",
    "loader = PyMuPDFLoader(file_path,\n",
    "        mode=\"single\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext',\n",
       " 'creator': 'Safari',\n",
       " 'creationdate': \"D:20250324210225Z00'00'\",\n",
       " 'source': './pubhub_docs/Warum Lachen gesund ist_DE.pdf',\n",
       " 'file_path': './pubhub_docs/Warum Lachen gesund ist_DE.pdf',\n",
       " 'total_pages': 4,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': 'Warum Lachen gesund ist',\n",
       " 'author': 'David Massimo',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': \"D:20250324210225Z00'00'\",\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20250324210225Z00'00'\",\n",
       " 'creationDate': \"D:20250324210225Z00'00'\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9119"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Loading + Parsing files\n",
    "#\n",
    "\n",
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import PyMuPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"./pubhub_docs/\",\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    # blob_parser=PyMuPDFParser(mode=\"single\"),\n",
    "    blob_parser=PyMuPDFParser(mode=\"single\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs[5].page_content)\n",
    "# docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization - Doc splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 68 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adf4daf9-763d-4195-a94e-eb58fea7ff52', 'c2571eaf-98d6-455d-9fbb-12ebd436160a', '39f684ef-094c-4285-bc10-428b37b007d8']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# example_messages = prompt.invoke(\n",
    "#     {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    "# ).to_messages()\n",
    "\n",
    "# assert len(example_messages) == 1\n",
    "# print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template = \"\"\"You are an helpful chatbot to support workers at Public Value Technologies gmbh (also known as pub.tech). \n",
    "# Use the following pieces of context to answer the question at the end.\n",
    "# If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "# Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "# If the query is in German you reply in german, otherwise in english.\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "\n",
    "# Helpful Answer:\"\"\"\n",
    "# prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an helpful chatbot for question-answering tasks supporting workers at Public Value Technologies gmbh (also known as pub.tech).\"        \n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know.\" \n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.documents import Document\n",
    "# from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "# class State(TypedDict):\n",
    "#     question: str\n",
    "#     context: List[Document]\n",
    "#     answer: str\n",
    "\n",
    "# # Nodes\n",
    "# def retrieve(state: State):\n",
    "#     retrieved_docs = vector_store.similarity_search(state[\"question\"],k=6)\n",
    "#     return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# def generate(state: State):    \n",
    "#     docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "#     messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "#     # print(messages)\n",
    "#     response = llm.invoke(messages)\n",
    "#     return {\"answer\": response}\n",
    "\n",
    "# # Control flow of the program (langgrap)h\n",
    "# from langgraph.graph import START, StateGraph\n",
    "\n",
    "# graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "# graph_builder.add_edge(START, \"retrieve\")\n",
    "# graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What should I do when doing a businesss trip?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (de7bc1d7-4d86-4399-9f95-2840e655826b)\n",
      " Call ID: de7bc1d7-4d86-4399-9f95-2840e655826b\n",
      "  Args:\n",
      "    query: business travel tips\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'producer': 'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext', 'creator': 'Safari', 'creationdate': \"D:20250324210537Z00'00'\", 'source': 'pubhub_docs/Business trips and travel expense guidelines.pdf', 'file_path': 'pubhub_docs/Business trips and travel expense guidelines.pdf', 'total_pages': 3, 'format': 'PDF 1.3', 'title': 'Business trips and travel expense guidelines', 'author': 'David Massimo', 'subject': '', 'keywords': '', 'moddate': \"D:20250324210537Z00'00'\", 'trapped': '', 'modDate': \"D:20250324210537Z00'00'\", 'creationDate': \"D:20250324210537Z00'00'\", 'start_index': 2460}\n",
      "Content: 24/03/25, 22:05\n",
      "Business trips and travel expense guidelines\n",
      "Page 2 of 3\n",
      "https://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx\n",
      "The balance between meeting business requirements, complying with legal\n",
      "requirements and ﬁnancial responsibility is crucial.\n",
      "Business Trips\n",
      "Business Trips\n",
      "Business Trips\n",
      "Business Trips\n",
      "Travel guidelines\n",
      "Travel guidelines\n",
      "Travel guidelines\n",
      "Travel guidelines\n",
      "\f24/03/25, 22:05\n",
      "Business trips and travel expense guidelines\n",
      "Page 3 of 3\n",
      "https://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx\n",
      "\n",
      "Source: {'producer': 'macOS Version 15.3.2 (Build 24D81) Quartz PDFContext', 'creator': 'Safari', 'creationdate': \"D:20250324210537Z00'00'\", 'source': 'pubhub_docs/Business trips and travel expense guidelines.pdf', 'file_path': 'pubhub_docs/Business trips and travel expense guidelines.pdf', 'total_pages': 3, 'format': 'PDF 1.3', 'title': 'Business trips and travel expense guidelines', 'author': 'David Massimo', 'subject': '', 'keywords': '', 'moddate': \"D:20250324210537Z00'00'\", 'trapped': '', 'modDate': \"D:20250324210537Z00'00'\", 'creationDate': \"D:20250324210537Z00'00'\", 'start_index': 1671}\n",
      "Content: transparently and to prevent abuse, we have drawn up corresponding\n",
      "transparently and to prevent abuse, we have drawn up corresponding\n",
      "transparently and to prevent abuse, we have drawn up corresponding\n",
      "guidelines for our organization for requesting business trips as well\n",
      "guidelines for our organization for requesting business trips as well\n",
      "guidelines for our organization for requesting business trips as well\n",
      "guidelines for our organization for requesting business trips as well\n",
      "as travel expense guidelines.\n",
      "as travel expense guidelines.\n",
      "as travel expense guidelines.\n",
      "as travel expense guidelines.\n",
      " \n",
      "This is because both employers and employees should be aware of their\n",
      "obligations and rights during business trips and act accordingly to ensure\n",
      "that the trip runs smoothly and safely.\n",
      "\f24/03/25, 22:05\n",
      "Business trips and travel expense guidelines\n",
      "Page 2 of 3\n",
      "https://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "According to the provided guidelines, it is recommended that you request a business trip transparently and follow the corresponding guidelines for your organization. This is to ensure that both employers and employees are aware of their obligations and rights during the trip.\n",
      "\n",
      "Additionally, it's mentioned that the balance between meeting business requirements, complying with legal requirements, and financial responsibility is crucial. However, the document does not provide a detailed checklist or specific steps to follow when doing a business trip.\n",
      "\n",
      "It's recommended to check the provided link for more information: https://publicvaluetech.sharepoint.com/sites/for-you/SitePages/en/Dienstreisen-und-Reisekostenrichtlinien.aspx.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What should I do when doing a businesss trip?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/david/Work/pub/pubhub_rag/RAG_chathistory_references.ipynb Cell 27\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Work/pub/pubhub_rag/RAG_chathistory_references.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# result = graph.invoke({\"question\": \"Was soll ich tun um urlaub zu buchen at pub.tech?\"})\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Work/pub/pubhub_rag/RAG_chathistory_references.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39minvoke({\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mWhat should I do when doing a businesss trip?\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/david/Work/pub/pubhub_rag/RAG_chathistory_references.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pprint\u001b[39m.\u001b[39mpp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mContext: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/david/Work/pub/pubhub_rag/RAG_chathistory_references.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pprint\u001b[39m.\u001b[39mpp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAnswer: \u001b[39m\u001b[39m{\u001b[39;00mresult[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'context'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "# result = graph.invoke({\"question\": \"Was soll ich tun um urlaub zu buchen at pub.tech?\"})\n",
    "result = graph.invoke({\"question\": \"What should I do when doing a businesss trip?\"})\n",
    "\n",
    "pprint.pp(f'Context: {result[\"context\"]}\\n\\n')\n",
    "pprint.pp(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "Table with embedding from the docs\n",
    "\n",
    "0 - 1 -> how a specific is being represented by that doc\n",
    "\n",
    "clustering of those documents. \n",
    "\n",
    "\n",
    "table of users -> decribing the topics for each user, \n",
    "\n",
    "\n",
    "consumption data (trend analysis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
